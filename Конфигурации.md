Содержание
==========
* [Terraform](#Terraform)
* [Ansible](#Ansible)
   * [nginx](#nginx)
   * [node-exporter](#node-exporter)
   * [prometheus](#prometheus)
   * [grafana](#grafana)
   * [elasticsearch](#elasticsearch)
   * [filebeat](#filebeat)
   * [kibana](#kibana)
   * [bastion](#bastion)
   
---------
## Terraform

`/home/admin/terraform/`

<details>

*<summary>meta.txt</summary>*

``` GO

#cloud-config
users:
  - name: admin
    groups: sudo
    shell: /bin/bash
    sudo: ['ALL=(ALL) NOPASSWD:ALL']
    ssh-authorized-keys:
            - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC3psGSU2mki9Pj/deYEU8soWQfrCz8mb9xNLJsoxjw5XflrOgxZyIQ15hy7obnLT6wj9DzJ6TWhiWHfYX1e6dCSaTWaI9ACa1CtJT5w2eS3fj+pi1THrTIXQnrz3VXX6hzGBRcHoTF2J34t6dcJU0g8JXffZjMQftA8IZK+fAXUNoaqrNKm67mQ5KtlzXazpZ6ZBceUZLsQqaQRQbJODJkcgjih3jN+fg89wCfL/zi7iN83EWgnVnRe1Ks4elGOhbyk74jJAOpw4+/yekYTdrxXMb4K4P5rbnYlCTIWmkFelEz4mAf9Ym1bILicvPOt+yRLp0TW+bf/ewQRMc7XlkpUOteuAQAwlkPmCJcD5cjzqbLukSq3PvTodcdYrUu4NTjZ475HqKhq61s0CCjvEQ/nCDdeNnmASopJLLo+9jE/kqUzoeczE5nGSgSQQowa9NjSDhvDw0PhEdRCnZY4DFvJDSHGmpfPLooqcqhsQe2zXLM7EOCCBX3e9O41lYpoSU= admin@terraform
```
</details>

<details>

*<summary>main.tf</summary>*

``` GO

terraform {
  required_providers {
    yandex = {
      source = "yandex-cloud/yandex"
    }
  }
  required_version = ">= 0.13"
}

provider "yandex" {
  cloud_id  = "b1gaipai88l7kddo0fdf"
  folder_id = "b1gfa8q3vq144o92ul90"
  zone      = "ru-central1-a"
}

resource "yandex_vpc_network" "porvatov" {
  name = "porvatov-network"
}

resource "yandex_vpc_subnet" "inner-web-1" {
  name           = "web-1-subnet"
  zone           = "ru-central1-a"
  network_id     = yandex_vpc_network.porvatov.id
  v4_cidr_blocks = ["10.0.1.0/28"]
  route_table_id = yandex_vpc_route_table.inner-to-nat.id 
}

resource "yandex_vpc_subnet" "inner-web-2" {
  name           = "web-2-subnet"
  zone           = "ru-central1-b"
  network_id     = yandex_vpc_network.porvatov.id
  v4_cidr_blocks = ["10.0.2.0/28"]
  route_table_id = yandex_vpc_route_table.inner-to-nat.id
}

resource "yandex_vpc_subnet" "inner-services" {
  name           = "inner-services-subnet"
  zone           = "ru-central1-c"
  network_id     = yandex_vpc_network.porvatov.id
  v4_cidr_blocks = ["10.0.3.0/27"]
  route_table_id = yandex_vpc_route_table.inner-to-nat.id
}

resource "yandex_vpc_subnet" "public" {
  name           = "public-subnet"
  zone           = "ru-central1-c"
  network_id     = yandex_vpc_network.porvatov.id
  v4_cidr_blocks = ["10.0.10.0/27"]
}

resource "yandex_compute_instance" "web-1" {
  name        = "vm-web-1"
  hostname    = "web-1"
  platform_id = "standard-v3"
  allow_stopping_for_update = true
  zone        = "ru-central1-a"

  resources {
    core_fraction = 20
    cores  = 2
    memory = 1
  }

  boot_disk {
    initialize_params {
      image_id = "fd843htdp8usqsiji0bb"
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.inner-web-1.id
    ip_address         = "10.0.1.3"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_compute_instance" "web-2" {
  name        = "vm-web-2"
  hostname    = "web-2"
  platform_id = "standard-v3"
  allow_stopping_for_update = true
  zone        = "ru-central1-b"

  resources {
    core_fraction = 20
    cores  = 2
    memory = 1
  }

  boot_disk {
    initialize_params {
      image_id = "fd843htdp8usqsiji0bb"
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.inner-web-2.id
    ip_address         = "10.0.2.3"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_alb_target_group" "web" {
  name = "web-target-group"

  target {
    ip_address = yandex_compute_instance.web-1.network_interface.0.ip_address
    subnet_id  = yandex_vpc_subnet.inner-web-1.id
  }

  target {
    ip_address = yandex_compute_instance.web-2.network_interface.0.ip_address
    subnet_id  = yandex_vpc_subnet.inner-web-2.id
  }
}

resource "yandex_alb_backend_group" "web" {
  name = "web-backend-group"

  http_backend {
    name             = "http-backend"
    weight           = 1
    port             = 80
    target_group_ids = [yandex_alb_target_group.web.id]
    load_balancing_config {
      panic_threshold = 90
    }
    healthcheck {
      timeout             = "10s"
      interval            = "2s"
      healthy_threshold   = 10
      unhealthy_threshold = 15
      http_healthcheck {
        path = "/"
      }
    }
  }
}

resource "yandex_alb_http_router" "web" {
  name = "web-http-router"
}

resource "yandex_alb_virtual_host" "root" {
  name           = "root-virtual-host"
  http_router_id = yandex_alb_http_router.web.id
  route {
    name = "root-path"
    http_route {
      http_match {
        path {
          prefix = "/"
        }
      }
      http_route_action {
        backend_group_id = yandex_alb_backend_group.web.id
        timeout          = "3s"
      }
    }
  }
}

resource "yandex_alb_load_balancer" "web" {
  name               = "web-load-balancer"
  network_id         = yandex_vpc_network.porvatov.id
  security_group_ids = [yandex_vpc_security_group.public-load-balancer.id, yandex_vpc_security_group.inner.id]

  allocation_policy {
    location {
      zone_id   = "ru-central1-c"
      subnet_id = yandex_vpc_subnet.inner-services.id
    }
  }

  listener {
    name = "listener1"
    endpoint {
      address {
        external_ipv4_address {
        }
      }
      ports = [80]
    }
    http {
      handler {
        http_router_id = yandex_alb_http_router.web.id
      }
    }
  }
}

resource "yandex_vpc_security_group" "inner" {
  name       = "inner-rules"
  network_id = yandex_vpc_network.porvatov.id

  ingress {
    protocol       = "ANY"
    description    = "allow any connection from inner subnets"
    v4_cidr_blocks = ["10.0.1.0/28", "10.0.2.0/28", "10.0.3.0/27", "10.0.10.0/27"]
  }

  egress {
    protocol       = "ANY"
    description    = "allow any outgoing connections"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "yandex_vpc_security_group" "public-load-balancer" {
  name       = "public-load-balancer-rules"
  network_id = yandex_vpc_network.porvatov.id

  ingress {
    protocol          = "ANY"
    description       = "Health checks"
    #port              = 80
    v4_cidr_blocks    = ["198.18.235.0/24", "198.18.248.0/24"]
    predefined_target = "loadbalancer_healthchecks"
  }

  ingress {
    protocol       = "TCP"
    description    = "allow HTTP connections from internet"
    v4_cidr_blocks = ["0.0.0.0/0"]
    port           = 80
  }

  ingress {
    protocol       = "ICMP"
    description    = "allow ping"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    protocol       = "ANY"
    description    = "allow any outgoing connection"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

output "external_ip_addres_load_balancer" {
  value = yandex_alb_load_balancer.web.listener.0.endpoint.0.address.0.external_ipv4_address
}

resource "yandex_vpc_route_table" "inner-to-nat" {
  network_id = yandex_vpc_network.porvatov.id

  static_route {
    destination_prefix = "0.0.0.0/0"
    next_hop_address   = yandex_compute_instance.bastion.network_interface.0.ip_address
  }
}

resource "yandex_compute_instance" "bastion" {
  name        = "vm-bastion"
  hostname    = "bastion"
  platform_id = "standard-v3"
  zone        = "ru-central1-c"

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = "fd82v0f4ufbnvm3b9s08" # nat-instance-ubuntu-18-04-lts-v20220520
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.public.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.inner.id, yandex_vpc_security_group.public-bastion.id]
    ip_address         = "10.0.10.5"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_vpc_security_group" "public-bastion" {
  name       = "public-bastion-rules"
  network_id = yandex_vpc_network.porvatov.id

  ingress {
    protocol       = "TCP"
    description    = "allow ssh connections from internet"
    v4_cidr_blocks = ["0.0.0.0/0"]
    port           = 22
  }

  ingress {
    protocol       = "ICMP"
    description    = "allow ping"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    protocol       = "ANY"
    description    = "allow any outgoing connection"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "yandex_compute_instance" "prometheus" {
  name        = "vm-prometheus"
  hostname    = "prometheus"
  platform_id = "standard-v3"
  zone        = "ru-central1-c"

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = "fd85jf9kn9r40o1neolo" # debian-11-v20220509
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.inner-services.id
    security_group_ids = [yandex_vpc_security_group.inner.id]
    ip_address         = "10.0.3.10"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_compute_instance" "grafana" {
  name        = "vm-grafana"
  hostname    = "grafana"
  platform_id = "standard-v3"
  zone        = "ru-central1-c"

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = "fd85jf9kn9r40o1neolo" # debian-11-v20220509
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.public.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.inner.id, yandex_vpc_security_group.public-grafana.id]
    ip_address         = "10.0.10.11"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_vpc_security_group" "public-grafana" {
  name       = "public-grafana-rules"
  network_id = yandex_vpc_network.porvatov.id

  ingress {
    protocol       = "TCP"
    description    = "allow grafana connections from internet"
    v4_cidr_blocks = ["0.0.0.0/0"]
    port           = 3000
  }

  ingress {
    protocol       = "ICMP"
    description    = "allow ping"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    protocol       = "ANY"
    description    = "allow any outgoing connection"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "yandex_compute_instance" "elastic" {
  name        = "vm-elastic"
  hostname    = "elastic"
  platform_id = "standard-v3"
  zone        = "ru-central1-c"

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = "fd85jf9kn9r40o1neolo" # debian-11-v20220509
      size     = 6
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.inner-services.id
    security_group_ids = [yandex_vpc_security_group.inner.id]
    ip_address         = "10.0.3.12"
    nat                = "true"
}

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_compute_instance" "kibana" {
  name        = "vm-kibana"
  hostname    = "kibana"
  platform_id = "standard-v3"
  zone        = "ru-central1-c"

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = "fd85jf9kn9r40o1neolo" # debian-11-v20220509
    }
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.public.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.inner.id, yandex_vpc_security_group.public-kibana.id]
    ip_address         = "10.0.10.13"
  }

  metadata = {
    user-data = "${file("./meta.txt")}"
  }
}

resource "yandex_vpc_security_group" "public-kibana" {
  name       = "public-kibana-rules"
  network_id = yandex_vpc_network.porvatov.id

  ingress {
    protocol       = "TCP"
    description    = "allow kibana connections from internet"
    v4_cidr_blocks = ["0.0.0.0/0"]
    port           = 5601
  }

  ingress {
    protocol       = "ICMP"
    description    = "allow ping"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    protocol       = "ANY"
    description    = "allow any outgoing connection"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

output "external_ip_addres_bastion-ssh" {
  value = yandex_compute_instance.bastion.network_interface.0.nat_ip_address
}

resource "yandex_compute_snapshot_schedule" "default" {
  name = "snap"

  schedule_policy {
    expression = "00 23 ? * *"
  }

  snapshot_count = 7

  disk_ids = [yandex_compute_instance.web-1.boot_disk[0].disk_id,
              yandex_compute_instance.web-2.boot_disk[0].disk_id,
              yandex_compute_instance.bastion.boot_disk[0].disk_id,
              yandex_compute_instance.prometheus.boot_disk[0].disk_id,
              yandex_compute_instance.grafana.boot_disk[0].disk_id, 
              yandex_compute_instance.elastic.boot_disk[0].disk_id,           
              yandex_compute_instance.kibana.boot_disk[0].disk_id,
             ]

}
```
</details>

## Ansible

`/etc/ansible/`

<details>

*<summary>ansible.cfg</summary>*

``` GO

[defaults]
inventory = ./hosts
remote_user = admin
roles_path = ./roles

[privilege_escalation]
become = True
become_user = root
become_method = sudo
```
</details>

<details>

*<summary>hosts</summary>*

``` GO

[bastion]
10.0.10.5 

[public-balancer]
84.252.131.55

[web]
10.0.1.3
10.0.2.3

[prometheus]
10.0.3.10

[grafana]
10.0.10.11 

[elastic]
10.0.3.12

[kibana]
10.0.10.13 
```
</details>

<details>

*<summary>play.yml</summary>*

``` GO

- hosts: web_servers
  become: true
  become_method: sudo
  become_user: root
  remote_user: admin
  roles:
   - role: nginx
     tags: nginx
   - role: node-exporter
     tags: exporter

  vars:
    nginx_user: www-data

- hosts: prometheus
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: prometheus
      tags: prom
      
- hosts: grafana
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: grafana
      tags: graf
      
- hosts: elasticsearch
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: elasticsearch
      tags: elastic

- hosts: web_servers
  become: true
  become_method: sudo
  become_user: root
  remote_user: admin
  roles:
   - role: filebeat
     tags: filebeat  
  
- hosts: kibana
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: kibana
      tags: kibana

- hosts: bastion
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: bastion
      tags: bastion
```
</details>

#### *nginx*

`ansible/nginx/`

<details>

*<summary>nginx.yml</summary>*

``` GO

- hosts: web
  become: yes
  tasks:
  - name: "install nginx"
    apt:
      name: nginx
      state: latest
      update_cache: yes

  - name: "create www directory"
    file:
      path: /var/www/{{ domain }}
      state: directory
      mode: '0775'

  - name: delete default nginx site
    file:
      path: /etc/nginx/sites-enabled/default
      state: absent
    notify: restart nginx

  - name: "copy custom config"
    copy:
      src: ./nginx/nginx.conf 
      dest: /etc/nginx/
    notify: restart nginx

  - name: copy nginx site.conf
    template:
      src: ./nginx/templates/site.conf.j2
      dest: /etc/nginx/sites-enabled/{{ domain }}
      owner: root
      group: root
      mode: '0644'
    notify: restart nginx

  - name: "copy website"
    copy:
      src: ./nginx/site/
      dest: /var/www/{{ domain }}
        
  handlers:
    - name: restart nginx
      service:
        name: nginx
        state: restarted
```
</details>

<details>

*<summary>static/index.html</summary>*

``` HTML

<html>
  <head>
<meta charset="UTF-8">

<center><h1>До новых встреч!</h1><center>
<img src="https://media1.giphy.com/media/Z21HJj2kz9uBG/giphy.gif?cid=ecf05e475ooe8qyeye1vjhbrmdo91n2u3fucegrsxzahnggt&ep=v1_gifs_search&rid=giphy.gif&ct=g" alt="GIF">

  </head>
  </html>
```
</details>

#### *node-exporter*

`roles/node-exporter/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

---
- import_tasks: preflight.yml
  tags:
    - node_exporter_install
    - node_exporter_configure
    - node_exporter_run

- import_tasks: install.yml
  become: true
  when:
    ( not __node_exporter_is_installed.stat.exists ) or
    ( __node_exporter_current_version_output.stderr_lines[0].split(" ")[2] != node_exporter_version ) or
    ( node_exporter_binary_local_dir | length > 0 )
  tags:
    - node_exporter_install

- import_tasks: selinux.yml
  become: true
  when: ansible_selinux.status == "enabled"
  tags:
    - node_exporter_configure

- import_tasks: configure.yml
  become: true
  tags:
    - node_exporter_configure

- name: Ensure Node Exporter is enabled on boot
  become: true
  systemd:
    daemon_reload: true
    name: node_exporter
    enabled: true
    state: started
  when:
    - not ansible_check_mode
  tags:
    - node_exporter_run
```
</details>

<details>

*<summary>tasks/install_node_exporter.yml</summary>*

``` GO

---
- name: Create the node_exporter group
  group:
    name: "{{ _node_exporter_system_group }}"
    state: present
    system: true
  when: _node_exporter_system_group != "root"

- name: Create the node_exporter user
  user:
    name: "{{ _node_exporter_system_user }}"
    groups: "{{ _node_exporter_system_group }}"
    append: true
    shell: /usr/sbin/nologin
    system: true
    create_home: false
    home: /
  when: _node_exporter_system_user != "root"

- block:
    - name: Download node_exporter binary to local folder
      become: false
      get_url:
        url: "https://github.com/prometheus/node_exporter/releases/download/v{{ node_exporter_version }}/node_exporter-{{ node_exporter_version }}.linux-{{ go_arch }}.tar.gz"
        dest: "/tmp/node_exporter-{{ node_exporter_version }}.linux-{{ go_arch }}.tar.gz"
        checksum: "sha256:{{ node_exporter_checksum }}"
        mode: '0644'
      register: _download_binary
      until: _download_binary is succeeded
      retries: 5
      delay: 2
      delegate_to: localhost
      check_mode: false

    - name: Unpack node_exporter binary
      become: false
      unarchive:
        src: "/tmp/node_exporter-{{ node_exporter_version }}.linux-{{ go_arch }}.tar.gz"
        dest: "/tmp"
        creates: "/tmp/node_exporter-{{ node_exporter_version }}.linux-{{ go_arch }}/node_exporter"
      delegate_to: localhost
      check_mode: false

    - name: Propagate node_exporter binaries
      copy:
        src: "/tmp/node_exporter-{{ node_exporter_version }}.linux-{{ go_arch }}/node_exporter"
        dest: "{{ _node_exporter_binary_install_dir }}/node_exporter"
        mode: 0755
        owner: root
        group: root
      notify: restart node_exporter
      when: not ansible_check_mode
  when: node_exporter_binary_local_dir | length == 0

- name: propagate locally distributed node_exporter binary
  copy:
    src: "{{ node_exporter_binary_local_dir }}/node_exporter"
    dest: "{{ _node_exporter_binary_install_dir }}/node_exporter"
    mode: 0755
    owner: root
    group: root
  when: node_exporter_binary_local_dir | length > 0
  notify: restart node_exporterc
```
</details>

<details>

*<summary>tasks/install.yml</summary>*

``` GO

---
- import_tasks: preflight.yml
  tags:
    - node_exporter_install
    - node_exporter_configure
    - node_exporter_run

- import_tasks: install.yml
  become: true
  when:
    ( not __node_exporter_is_installed.stat.exists ) or
    ( __node_exporter_current_version_output.stderr_lines[0].split(" ")[2] != node_exporter_version ) or
    ( node_exporter_binary_local_dir | length > 0 )
  tags:
    - node_exporter_install

- import_tasks: selinux.yml
  become: true
  when: ansible_selinux.status == "enabled"
  tags:
    - node_exporter_configure

- import_tasks: configure.yml
  become: true
  tags:
    - node_exporter_configure

- name: Ensure Node Exporter is enabled on boot
  become: true
  systemd:
    daemon_reload: true
    name: node_exporter
    enabled: true
    state: started
  when:
    - not ansible_check_mode
  tags:
    - node_exporter_run
```
</details>

#### *prometheus*

`roles/prometheus/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

---
- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - prometheus_configure
    - prometheus_install
    - prometheus_run

- include: preflight.yml
  tags:
    - prometheus_configure
    - prometheus_install
    - prometheus_run

- include: install.yml
  become: true
  tags:
    - prometheus_install

- include: configure.yml
  become: true
  tags:
    - prometheus_configure

- name: ensure prometheus service is started and enabled
  become: true
  systemd:
    daemon_reload: true
    name: prometheus
    state: started
    enabled: true
  tags:
    - prometheus_run
```
</details>

<details>

*<summary>tasks/install_prometheus.yml</summary>*

``` GO

---
- name: create prometheus system group
  group:
    name: prometheus
    system: true
    state: present

- name: create prometheus system user
  user:
    name: prometheus
    system: true
    shell: "/usr/sbin/nologin"
    group: prometheus
    createhome: false
    home: "{{ prometheus_db_dir }}"

- name: create prometheus data directory
  file:
    path: "{{ prometheus_db_dir }}"
    state: directory
    owner: prometheus
    group: prometheus
    mode: 0755

- name: create prometheus configuration directories
  file:
    path: "{{ item }}"
    state: directory
    owner: root
    group: prometheus
    mode: 0770
  with_items:
    - "{{ prometheus_config_dir }}"
    - "{{ prometheus_config_dir }}/rules"
    - "{{ prometheus_config_dir }}/file_sd"

- block:
    - name: download prometheus binary to local folder
      become: false
      get_url:
        url: "https://github.com/prometheus/prometheus/releases/download/v{{ prometheus_version }}/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}.tar.gz"
        dest: "/tmp/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}.tar.gz"
        checksum: "sha256:{{ __prometheus_checksum }}"
      register: _download_archive
      until: _download_archive is succeeded
      retries: 5
      delay: 2
      # run_once: true # <-- this cannot be set due to multi-arch support
      delegate_to: localhost
      check_mode: false

    - name: unpack prometheus binaries
      become: false
      unarchive:
        src: "/tmp/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}.tar.gz"
        dest: "/tmp"
        creates: "/tmp/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}/prometheus"
      delegate_to: localhost
      check_mode: false

    - name: propagate official prometheus and promtool binaries
      copy:
        src: "/tmp/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}/{{ item }}"
        dest: "{{ _prometheus_binary_install_dir }}/{{ item }}"
        mode: 0755
        owner: root
        group: root
      with_items:
        - prometheus
        - promtool
      notify:
        - restart prometheus

    - name: propagate official console templates
      copy:
        src: "/tmp/prometheus-{{ prometheus_version }}.linux-{{ go_arch }}/{{ item }}/"
        dest: "{{ prometheus_config_dir }}/{{ item }}/"
        mode: 0644
        owner: root
        group: root
      with_items:
        - console_libraries
        - consoles
      notify:
        - restart prometheus
  when:
    - prometheus_binary_local_dir | length == 0
    - not prometheus_skip_install

- name: propagate locally distributed prometheus and promtool binaries
  copy:
    src: "{{ prometheus_binary_local_dir }}/{{ item }}"
    dest: "{{ _prometheus_binary_install_dir }}/{{ item }}"
    mode: 0755
    owner: root
    group: root
  with_items:
    - prometheus
    - promtool
  when:
    - prometheus_binary_local_dir | length > 0
    - not prometheus_skip_install
  notify:
    - restart prometheus

- name: create systemd service unit
  template:
    src: prometheus.service.j2
    dest: /etc/systemd/system/prometheus.service
    owner: root
    group: root
    mode: 0644
  notify:
    - restart prometheus

- name: Install SELinux dependencies
  package:
    name: "{{ item }}"
    state: present
  with_items: "{{ prometheus_selinux_packages }}"
  register: _install_packages
  until: _install_packages is succeeded
  retries: 5
  delay: 2
  when:
    - ansible_version.full is version('2.4', '>=')
    - ansible_selinux.status == "enabled"

- name: Allow prometheus to bind to port in SELinux
  seport:
    ports: "{{ prometheus_web_listen_address.split(':')[1] }}"
    proto: tcp
    setype: http_port_t
    state: present
  when:
    - ansible_version.full is version('2.4', '>=')
    - ansible_selinux.status == "enabled"c
```
</details>

<details>

#### *grafana*

`roles/grafana/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

---
- name: Create User grafana
  user:
    name: grafana
    create_home: no
    shell: /bin/false
  
- name: Create directories for Grafana
  file:
    path: "/tmp/grafana"
    state: directory

- name: Download Grafana
  copy:
    src: "/etc/ansible/roles/grafana/static/grafana_10.0.2_amd64.deb"
    dest: /tmp/grafana


- name: Install Grafana
  apt:
    deb: "/tmp/grafana/grafana_10.0.2_amd64.deb"

- name: Copy template
  copy:
    src: "/etc/ansible/roles/grafana/templates/main.yml"
    dest: /etc/grafana/provisioning/datasources

- name: Create directories for Dashboards
  file:
    path: "/var/lib/grafana/dashboards"
    state: directory

- name: Copy json
  copy:
    src: "/etc/ansible/roles/grafana/templates/metrics.json"
    dest: /var/lib/grafana/dashboards
    owner: grafana
    group: grafana
```
</details>

<details>

*<summary>templates/main.yml</summary>*

``` GO

apiVersion: 1
 
datasources:
  - name: Prometheus
    type: prometheus
    version: 1
    access: proxy
    orgId: 1
    basicAuth: false
    editable: false
    url: http://10.0.3.10:9090
```
</details>


#### *elasticsearch*

`roles/elasticsearch/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

---

- name: Create User elasticsearch
  user:
    name: elasticsearch
    create_home: no
    shell: /bin/false

- name: Create directories for elasticsearch
  file:
    path: "/tmp/elasticsearch"
    state: directory

- name: Download elasticsearch
  copy:
    src: "/etc/ansible/roles/Elasticsearch/static/elasticsearch-8.8.2-amd64.deb"
    dest: /tmp/elasticsearch

      #- name: Install java
      # apt:
      # name=default-jre
      # state=latest

- name: Install elasticsearch
  apt:
    deb: "/tmp/elasticsearch/elasticsearch-8.8.2-amd64.deb"


- name: Copy CA to ansible
  ansible.builtin.fetch:
    src: /etc/elasticsearch/certs/http_ca.crt
    dest: /etc/ansible/roles/Elasticsearch/static/
```
</details>


#### *filebeat*

`roles/filebeat/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

---
# tasks file for filebeat

- name: Create directories for filebeat
  file:
    path: "/tmp/filebeat"
    state: directory

- name: Download filebeat
  copy:
    src: "/etc/ansible/roles/filebeat/files/filebeat-8.5.2-amd64.deb"
    dest: /tmp/filebeat

- name: Install filebeat
  apt:
    deb: "/tmp/filebeat/filebeat-8.5.2-amd64.deb"

- name: Copy template
  copy:
    src: "/etc/ansible/roles/filebeat/templates/filebeat.yml"
    dest: /etc/filebeat

- name: Copy module
  copy:
    src: "/etc/ansible/roles/filebeat/templates/nginx.yml"
    dest: /etc/filebeat/modules.d/

- name: Copy ca
  copy:
    src: "/etc/ansible/roles/kibana/static/http_ca.crt"
    dest: /etc/filebeatc
```
</details>

<details>

*<summary>templates/filebeat</summary>*

``` GO

---
    filebeat.config.modules:
  enabled: true
  path: /etc/filebeat/modules.d/*.yml


output.elasticsearch:
  hosts: ["http://10.0.3.12:9200"]
  username: "elastic"
  password: "YuL8Kwog3e56O8VxMKli"
  ssl:
    enabled: true
    certificate_authorities: ["/etc/filebeat/http_ca.crt"]c
```
</details>

<details>

*<summary>templates/nginx</summary>*

``` GO

- module: nginx
  access:
    enabled: true
    var.paths: ["/var/log/nginx/access.log*"]
  error:
    enabled: true
    var.paths: ["/var/log/nginx/error.log*"]
```
</details>

#### *kibana*

`roles/kibana/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

- name: Create directories for kibana
  file:
    path: "/tmp/kibana"
    state: directory

- name: Download kibana
  copy:
    src: "/etc/ansible/roles/kibana/static/kibana-8.8.2-amd64.deb"
    dest: /tmp/kibana

- name: Install kibana
  apt:
    deb: "/tmp/kibana/kibana-8.8.2-amd64.deb"

- name: Copy template
  copy:
    src: "/etc/ansible/roles/kibana/templates/kibana.yml"
    dest: /etc/kibana

- name: Create directories for ca
  file:
    path: "/etc/kibana/certs/"
    state: directory

- name: Copy ca
  copy:
    src: "/etc/ansible/roles/kibana/static/http_ca.crt"
    dest: /etc/kibana/certs/
```
</details>

<details>

*<summary>templates/kibana.yml</summary>*

``` GO

server.host: "0.0.0.0"

# =================== System: Elasticsearch ===================
# The URLs of the Elasticsearch instances to use for all your queries.
elasticsearch.hosts: ["https://192.168.2.4:9200"]

elasticsearch.username: "kibana_system"
elasticsearch.password: "2sefwI0SFcHpQYzzevpb"

logging:
  appenders:
    file:
      type: file
      fileName: /var/log/kibana/kibana.log
      layout:
        type: json
  root:
    appenders:
      - default
      - file
```
</details>

#### *bastion*

`roles/bastion/`

<details>

*<summary>tasks/main.yml</summary>*

``` GO

- hosts: all
  become: true
  become_method: sudo
  become_user: root
  remote_user: admin

- name: Copy id_rsa
  copy:
    src: /home/admin/.ssh/id_rsa
    dest: /home/admin/.ssh
    owner: admin
    group: admin
    mode: '0600'

```
</details>